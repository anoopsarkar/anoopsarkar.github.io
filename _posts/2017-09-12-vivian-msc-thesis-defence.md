---
layout: post
title: "Vivian passes her MSc thesis exam"
root: ../../
---

On September 12th at 2pm in TASC1 9204 West, Vivian Kou successfully defended her MSc
thesis on the topic of "Speed versus Accuracy in Neural Sequence Tagging for
Natural Language Processing". Congratulations Vivian!

Abstract:

Sequence Tagging, including part of speech tagging and named entity
recognition, is an important task in NLP. Recurrent neural network models such
as Bidirectional LSTMs have produced impressive results on sequence tagging. In
this work, we first present a simple and fast greedy sequence tagging system
using different types of feedforward neural net- work models. Then we show the
speed and accuracy comparison between Bidirectional LSTMs and feedforward
models. Besides the feedforward and the Bidirectional LSTM models, we propose
two new models based on Mention2Vec by Stratos (2016): Feedforward-Mention2Vec
for Named Entity Recognition and BPE-Mention2Vec for Part-of-Speech Tagging.
Feedforward-Mention2Vec predicts named entity boundaries first and then
predicts types of named entities. BPE-Mention2Vec uses the Byte Pair Encoding
algorithm to segment words in a sequence first and then predicts the
Part-of-Speech tags for the subword spans. We carefully design the experiments
to demonstrate the speed and accuracy trade- off in different models. The
empirical results reveal that feedforward models can achieve comparable
accuracy and faster speed than recurrent models for Part-of-Speech tagging, and
Feedforward-Mention2Vec is competitive with the fully structured BiLSTM model
for Named Entity Recognition while being more scalable in the number of named
entity types.

M.Sc. Examining Committee:

* Dr. Anoop Sarkar, Senior Supervisor
* Dr. Fred Popowich, Supervisor
* Dr. Jiannan Wang, Internal Examiner
* Dr. Arrvindh Shriraman, Chair
